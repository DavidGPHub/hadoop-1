# Single Node Tensorflow on YARN

## Example Yarnfile (Using GPU and talk to security HDFS)

```
yarn application -destroy distributed-tf ; curl --negotiate -u: -H "Content-Type: application/json" -X POST http://ctr-e138-1518143905142-261690-01-000004.hwx.site:8088/app/v1/services?doAs=ambari-qa -d '{
    "name": "distributed-tf",
    "version": "1.0.0",
    "components": [
        {
            "artifact" : {
              "id" : "wtan/tf-on-yarn-example:1.3.0-gpu-003",
              "type" : "DOCKER"
            },
            "name": "worker",
            "dependencies": [],
            "resource": {
                "cpus": 1,
                "memory": "4096",
                "additional" : {
                  "yarn.io/gpu" : {
                    "value" : 2
                   }
                }
            },
            "launch_command": "export HADOOP_HDFS_HOME=/hadoop-3.1.0; export HADOOP_HOME=; export HADOOP_YARN_HOME=; export HADOOP_CONF_DIR=/etc/hadoop/conf; export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64/jre/; export CLASSPATH=\\`\\$HADOOP_HDFS_HOME/bin/hadoop classpath --glob\\`; export LD_LIBRARY_PATH=\\$LD_LIBRARY_PATH:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/amd64/server/; cd /test/models/tutorials/image/cifar10_estimator  && ls -l && python cifar10_main.py --data-dir=hdfs://default/tmp/cifar-10-data --job-dir=hdfs://default/tmp/cifar-10-jobdir --num-gpus=1 --train-batch-size=16 --train-steps=40000",
            "number_of_containers": 1,
            "run_privileged_container": false
        }
    ],
    "kerberos_principal" : {
      "principal_name" : "ambari-qa@EXAMPLE.COM",
      "keytab" : "file:///etc/security/keytabs/smokeuser.headless.keytab"
    }
}'
```
