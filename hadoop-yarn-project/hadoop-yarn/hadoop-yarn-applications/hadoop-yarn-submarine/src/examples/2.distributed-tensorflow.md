# Distributed Tensorflow on YARN

## Yarnfile (GPU + Security HDFS)
```
hadoop fs -rmr /tmp/cifar-10-jobdir; yarn application -destroy distributed-tf ; curl --negotiate -u: -H "Content-Type: application/json" -X POST http://ctr-e138-1518143905142-261690-01-000004.hwx.site:8088/app/v1/services?doAs=ambari-qa -d '{
    "name": "distributed-tf",
    "version": "1.0.0",
    "components": [
        {
            "name": "master",
            "dependencies": [],
            "resource": {
                "cpus": 1,
                "memory": "4096",
                "additional" : {
                  "yarn.io/gpu" : {
                    "value" : 1
                   }
                }
            },
            "artifact" : {
              "id" : "wtan/tf-on-yarn-example:1.3.0-gpu-003",
              "type" : "DOCKER"
            },
            "launch_command": "export HADOOP_HDFS_HOME=/hadoop-3.1.0; export HADOOP_HOME=; export HADOOP_YARN_HOME=; export CLASSPATH=\\`\\$HADOOP_HDFS_HOME/bin/hadoop classpath --glob\\`; export LD_LIBRARY_PATH=\\$LD_LIBRARY_PATH:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/amd64/server/; cd /test/models/tutorials/image/cifar10_estimator  && ls -l && python cifar10_main.py --data-dir=hdfs://default/tmp/cifar-10-data --job-dir=hdfs://default/tmp/cifar-10-jobdir --num-gpus=1  --train-steps=10000  --eval-batch-size=16 --train-batch-size=16 --sync",
            "number_of_containers": 1,
            "run_privileged_container": false
        },
        {
            "name": "worker",
            "dependencies": [],
            "resource": {
                "cpus": 1,
                "memory": "4096",
                "additional" : {
                  "yarn.io/gpu" : {
                    "value" : 1
                   }
                }
            },
            "artifact" : {
              "id" : "wtan/tf-on-yarn-example:1.3.0-gpu-003",
              "type" : "DOCKER"
            },
            "launch_command": "export HADOOP_HDFS_HOME=/hadoop-3.1.0; export HADOOP_HOME=; export HADOOP_YARN_HOME=; export CLASSPATH=\\`\\$HADOOP_HDFS_HOME/bin/hadoop classpath --glob\\`; export LD_LIBRARY_PATH=\\$LD_LIBRARY_PATH:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/amd64/server/; cd /test/models/tutorials/image/cifar10_estimator  && ls -l && python cifar10_main.py --data-dir=hdfs://default/tmp/cifar-10-data --job-dir=hdfs://default/tmp/cifar-10-jobdir --num-gpus=1 --train-steps=10000 --eval-batch-size=16 --train-batch-size=16 --sync",
            "number_of_containers": 1,
            "run_privileged_container": false
        },
        {
            "name": "ps",
            "dependencies": [],
            "resource": {
                "cpus": 1,
                "memory": "2048",
                "additional" : {
                  "yarn.io/gpu" : {
                    "value" : 1
                   }
                }
            },
            "artifact" : {
              "id" : "wtan/tf-on-yarn-example:1.3.0-gpu-003",
              "type" : "DOCKER"
            },
            "launch_command": "export HADOOP_HDFS_HOME=/hadoop-3.1.0; export HADOOP_HOME=; export HADOOP_YARN_HOME=; export CLASSPATH=\\`\\$HADOOP_HDFS_HOME/bin/hadoop classpath --glob\\`; export LD_LIBRARY_PATH=\\$LD_LIBRARY_PATH:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/amd64/server/; cd /test/models/tutorials/image/cifar10_estimator  && ls -l && python cifar10_main.py --data-dir=hdfs://default/tmp/cifar-10-data --job-dir=hdfs://default/tmp/cifar-10-jobdir",
            "number_of_containers": 1,
            "run_privileged_container": false
        }
    ],
    "configuration": {
        "properties": {},
        "env": {
            "TF_CONFIG": "{ \\\"cluster\\\": { \\\"master\\\": [\\\"master-0.distributed-tf.ambari-qa.test.com:8000\\\"], \\\"ps\\\": [\\\"ps-0.distributed-tf.ambari-qa.test.com:8000\\\"], \\\"worker\\\": [\\\"worker-0.distributed-tf.ambari-qa.test.com:8000\\\"] }, \\\"task\\\": { \\\"type\\\": \\\"${COMPONENT_NAME}\\\", \\\"index\\\": ${COMPONENT_ID} }, \\\"environment\\\": \\\"cloud\\\" }",
            "HADOOP_CONF_DIR" : "/etc/hadoop/conf",
            "JAVA_HOME" : "/usr/lib/jvm/java-8-openjdk-amd64/jre/",
            "YARN_CONTAINER_RUNTIME_DOCKER_CONTAINER_NETWORK": "bridge"
        }
    },
    "kerberos_principal" : {
      "principal_name" : "ambari-qa@EXAMPLE.COM",
      "keytab" : "file:///etc/security/keytabs/smokeuser.headless.keytab"
    }
}'
```

## Yarnfile (CPU + Non-Security HDFS)
```
{
    "name": "distributed-tf",
    "version": "1.0.0",
    "components": [
        {
            "name": "master",
            "dependencies": [],
            "resource": {
                "cpus": 1,
                "memory": "4096"
            },
            "artifact" : {
              "id" : "wtan/tf-on-yarn-example:1.3.0-cpu-001",
              "type" : "DOCKER"
            },
            "launch_command": "export HADOOP_HDFS_HOME=/hadoop-3.1.0; export HADOOP_HOME=; export HADOOP_YARN_HOME=; export CLASSPATH=\\`\\$HADOOP_HDFS_HOME/bin/hadoop classpath --glob\\`; export LD_LIBRARY_PATH=\\$LD_LIBRARY_PATH:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/amd64/server/; cd /test/models/tutorials/image/cifar10_estimator && python cifar10_main.py --data-dir=hdfs://default/tmp/cifar-10-data --job-dir=hdfs://default/tmp/cifar-10-jobdir --train-steps=10000 --num-gpus=0 --eval-batch-size=16 --train-batch-size=16 --sync",
            "number_of_containers": 1,
            "run_privileged_container": false
        },
        {
            "name": "worker",
            "dependencies": [],
            "resource": {
                "cpus": 1,
                "memory": "4096"
            },
            "artifact" : {
              "id" : "wtan/tf-on-yarn-example:1.3.0-cpu-001",
              "type" : "DOCKER"
            },
            "launch_command": "export HADOOP_HDFS_HOME=/hadoop-3.1.0; export HADOOP_HOME=; export HADOOP_YARN_HOME=; export CLASSPATH=\\`\\$HADOOP_HDFS_HOME/bin/hadoop classpath --glob\\`; export LD_LIBRARY_PATH=\\$LD_LIBRARY_PATH:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/amd64/server/; cd /test/models/tutorials/image/cifar10_estimator && python cifar10_main.py --data-dir=hdfs://default/tmp/cifar-10-data --job-dir=hdfs://default/tmp/cifar-10-jobdir --train-steps=10000 --num-gpus=0 --eval-batch-size=16 --train-batch-size=16 --sync",
            "number_of_containers": 1,
            "run_privileged_container": false
        },
        {
            "name": "ps",
            "dependencies": [],
            "resource": {
                "cpus": 1,
                "memory": "2048"
            },
            "artifact" : {
              "id" : "wtan/tf-on-yarn-example:1.3.0-cpu-001",
              "type" : "DOCKER"
            },
            "launch_command": "export HADOOP_HDFS_HOME=/hadoop-3.1.0; export HADOOP_HOME=; export HADOOP_YARN_HOME=; export CLASSPATH=\\`\\$HADOOP_HDFS_HOME/bin/hadoop classpath --glob\\`; export LD_LIBRARY_PATH=\\$LD_LIBRARY_PATH:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/amd64/server/; cd /test/models/tutorials/image/cifar10_estimator  && ls -l && python cifar10_main.py --data-dir=hdfs://default/tmp/cifar-10-data --job-dir=hdfs://default/tmp/cifar-10-jobdir --num-gpus=0",
            "number_of_containers": 1,
            "run_privileged_container": false
        }
    ],
    "configuration": {
        "properties": {},
        "env": {
            "TF_CONFIG": "{ \\\"cluster\\\": { \\\"master\\\": [\\\"master-0.distributed-tf.ambari-qa.test.com:8000\\\"], \\\"ps\\\": [\\\"ps-0.distributed-tf.ambari-qa.test.com:8000\\\"], \\\"worker\\\": [\\\"worker-0.distributed-tf.ambari-qa.test.com:8000\\\"] }, \\\"task\\\": { \\\"type\\\": \\\"${COMPONENT_NAME}\\\", \\\"index\\\": ${COMPONENT_ID} }, \\\"environment\\\": \\\"cloud\\\" }",
            "HADOOP_CONF_DIR" : "/etc/hadoop/conf",
            "JAVA_HOME" : "/usr/lib/jvm/java-8-openjdk-amd64/jre/",
            "YARN_CONTAINER_RUNTIME_DOCKER_CONTAINER_NETWORK": "bridge"
        }
    },
    "kerberos_principal" : {
      "principal_name" : "ambari-qa@EXAMPLE.COM",
      "keytab" : "file:///etc/security/keytabs/smokeuser.headless.keytab"
    }
}
```

Save the Yarnfile to a local file.

Use following command to run:

```
hadoop fs -rmr /tmp/cifar-10-jobdir;
yarn application -destroy distributed-tf; 
yarn app -launch distributed-tf <path-to-saved-yarnfile>
```

Or you can use curl to post the yarnfile.

```
hadoop fs -rmr /tmp/cifar-10-jobdir;
yarn application -destroy distributed-tf;
curl --negotiate -u: -H "Content-Type: application/json" \
  -X POST http://<RM-host>:8088/app/v1/services -d '... content of Yarnfile...'
```